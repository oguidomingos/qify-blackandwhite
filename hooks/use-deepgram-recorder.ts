import { useState, useRef, useCallback } from 'react';

interface UseDeepgramRecorderProps {
  onTranscriptComplete: (text: string) => void;
}

export function useDeepgramRecorder({ onTranscriptComplete }: UseDeepgramRecorderProps) {
  const [isRecording, setIsRecording] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [error, setError] = useState<string | null>(null);
  const [isProcessing, setIsProcessing] = useState(false);

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const streamRef = useRef<MediaStream | null>(null);

  const startRecording = useCallback(async () => {
    console.log('ðŸŽ™ï¸ [Deepgram] Starting recording...');

    try {
      // Request microphone access
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 16000 // Optimal for speech recognition
        }
      });

      console.log('âœ… [Deepgram] Microphone access granted');
      streamRef.current = stream;

      // Create MediaRecorder
      const mimeType = MediaRecorder.isTypeSupported('audio/webm;codecs=opus')
        ? 'audio/webm;codecs=opus'
        : 'audio/webm';

      console.log('ðŸŽµ [Deepgram] Using MIME type:', mimeType);

      const mediaRecorder = new MediaRecorder(stream, {
        mimeType,
        audioBitsPerSecond: 16000
      });

      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
          console.log('ðŸ“¦ [Deepgram] Audio chunk received:', event.data.size, 'bytes');
        }
      };

      mediaRecorder.onstop = async () => {
        console.log('ðŸ›‘ [Deepgram] Recording stopped, processing audio...');
        setIsProcessing(true);

        // Combine all chunks into a single blob
        const audioBlob = new Blob(audioChunksRef.current, { type: mimeType });
        console.log('ðŸ“¦ [Deepgram] Total audio size:', audioBlob.size, 'bytes');

        if (audioBlob.size === 0) {
          console.warn('âš ï¸ [Deepgram] Audio blob is empty');
          setError('Nenhum Ã¡udio foi capturado. Tente novamente.');
          setIsProcessing(false);
          return;
        }

        // Send to API for transcription
        try {
          console.log('ðŸ“¤ [Deepgram] Sending audio to transcription API...');

          const formData = new FormData();
          formData.append('audio', audioBlob, 'recording.webm');

          const response = await fetch('/api/transcribe', {
            method: 'POST',
            body: formData,
          });

          console.log('ðŸ“¥ [Deepgram] Response status:', response.status);

          if (!response.ok) {
            const errorData = await response.json().catch(() => ({ error: 'Unknown error' }));
            throw new Error(errorData.error || `HTTP ${response.status}`);
          }

          const data = await response.json();
          console.log('âœ… [Deepgram] Transcription received:', data);

          if (data.success && data.transcript) {
            const transcriptText = data.transcript.trim();
            console.log('ðŸ“ [Deepgram] Final transcript:', transcriptText);

            setTranscript(transcriptText);
            onTranscriptComplete(transcriptText);
          } else {
            throw new Error(data.error || 'No transcript returned');
          }
        } catch (err) {
          console.error('âŒ [Deepgram] Transcription error:', err);
          setError(err instanceof Error ? err.message : 'Erro ao transcrever Ã¡udio');
        } finally {
          setIsProcessing(false);
        }

        // Cleanup
        audioChunksRef.current = [];
      };

      mediaRecorder.onerror = (event: any) => {
        console.error('âŒ [Deepgram] MediaRecorder error:', event.error);
        setError('Erro ao gravar Ã¡udio');
        setIsRecording(false);
      };

      mediaRecorderRef.current = mediaRecorder;
      mediaRecorder.start();
      setIsRecording(true);
      setError(null);
      setTranscript('');

      console.log('ðŸŽ¤ [Deepgram] Recording started');
    } catch (err) {
      console.error('âŒ [Deepgram] Error starting recording:', err);
      setError(err instanceof Error ? err.message : 'Erro ao acessar microfone');
    }
  }, [onTranscriptComplete]);

  const stopRecording = useCallback(() => {
    console.log('ðŸ›‘ [Deepgram] Stopping recording...');

    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
    }

    // Stop all tracks
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => {
        track.stop();
        console.log('ðŸ”‡ [Deepgram] Stopped track:', track.kind);
      });
      streamRef.current = null;
    }
  }, []);

  const resetTranscript = useCallback(() => {
    setTranscript('');
    audioChunksRef.current = [];
  }, []);

  return {
    isRecording,
    transcript,
    error,
    isProcessing,
    startRecording,
    stopRecording,
    resetTranscript
  };
}
